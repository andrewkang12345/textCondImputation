Vector-Conditioned Trajectory Imputation (Basketball, 8Ã—5 Grid)

Short version: This project predicts a single playerâ€™s future movement when that player is â€œmaskedâ€ (hidden) for parts of a play.
The model is guided by a simple 8Ã—5 grid of the court (40 regions). You can provide those regions directly, or even write a short natural-language description (e.g., â€œhe ran toward the goal and then drifted to the right wingâ€), which we translate into grid IDs with the OpenAI API.

<p align="center">
  <img src="test.gif" alt="Prediction vs Ground Truth demo" width="720"/>
</p>


In the GIF:
	â€¢	Green = Ground Truth path for the masked player
	â€¢	Blue = Modelâ€™s predicted path for the masked player
	â€¢	Other players are shown in team colors
	â€¢	Left-to-right offense; coordinates are normalized to the court

â¸»

What you can do
	â€¢	ğŸ§  Train a Transformer or Diffusion model that imputes masked trajectories
	â€¢	ğŸ—ºï¸ Condition the prediction using a per-timestep 40-way one-hot region signal
	â€¢	âœï¸ Describe the intended path in plain English â€” weâ€™ll map it to region IDs automatically (optional)
	â€¢	ğŸï¸ Export GIFs overlaying predictions and ground truth (like test.gif)
	â€¢	ğŸ“ˆ Report metrics (ADE, FDE, collision rate, smoothness)

â¸»

1) Installation

# Python 3.9+ recommended
python -m venv .venv
source .venv/bin/activate        # Windows: .venv\Scripts\activate

pip install -r requirements.txt  # or pip install torch torchvision torchaudio ...
                                 # plus numpy, pillow, imageio, tqdm, transformers, etc.

Optional (only if youâ€™ll use --prompt):
export OPENAI_API_KEY=your_key_here

â¸»

2) Data format

We expect a pickle file with a single NumPy array shaped (N, T, A, 2):
	â€¢	N = number of sequences (plays)
	â€¢	T = timesteps per sequence
	â€¢	A = number of agents/players
	â€¢	Last axis (x, y) in feet or already [0,1] normalized
(If values look like feet, we auto-normalize by (x/94, y/50).)

Example paths used in scripts:
	â€¢	Train: /.../basketball/train_clean.p
	â€¢	Val/Test: /.../basketball/test_clean.p

â¸»

3) Court regions (conditioning signal)

We discretize the court into an 8 (x) Ã— 5 (y) grid â†’ R = 40 bins.
IDs are row-major:

id = y * 8 + x
x âˆˆ {0..7} leftâ†’right    y âˆˆ {0..4} bottomâ†’top

The model receives a one-hot vector of length 40 for the masked agent at each timestep.
You can provide these region IDs in 3 ways (priority order):
	1.	JSON list of integers: --region_ids_json "[0,0,1,1,2,...]" (length must equal T)
	2.	Natural language: --prompt "â€¦" (requires OPENAI_API_KEY)
â†’ We convert your text into T grid IDs automatically.
	3.	Oracle (default): we compute IDs from the masked agentâ€™s ground-truth path (for testing).

â¸»

4) Train

python experiment.py \
  --train_traj /path/to/train_clean.p \
  --val_traj   /path/to/test_clean.p \
  --out_dir outputs \
  --epochs 30

This runs the XL Transformer baseline (VectorConditionedImputerXL) and writes:
	â€¢	checkpoints to outputs/vec_xl_baseline/
	â€¢	a results row to outputs/results.csv
	â€¢	TensorBoard logs (if available)

â¸»

5) Inference & GIFs

A) Oracle conditioning (no API needed)

python inference.py \
  --checkpoint outputs/vec_xl_baseline/best.pt \
  --traj_file /path/to/test_clean.p \
  --masked_agent 1 \
  --gif_out test.gif \
  --court_png court.png \
  --metrics

B) Natural-language conditioning (OpenAI)

export OPENAI_API_KEY=your_key_here

python inference.py \
  --checkpoint outputs/vec_xl_baseline/best.pt \
  --traj_file /path/to/test_clean.p \
  --masked_agent 1 \
  --prompt "He started near half court, drove toward the rim, then drifted out to the right wing." \
  --gif_out test.gif \
  --court_png court.png \
  --metrics

C) Explicit region IDs

python inference.py \
  --checkpoint outputs/vec_xl_baseline/best.pt \
  --traj_file /path/to/test_clean.p \
  --masked_agent 1 \
  --region_ids_json "[0,0,0,1,1,2,2,2,3,3, ... up to T entries ...]" \
  --gif_out test.gif \
  --court_png court.png \
  --metrics

What the GIF shows
	â€¢	Green path & dots: Ground-truth positions of the masked agent
	â€¢	Blue path & dots: Model predictions for the masked agent
	â€¢	Other players: Team-colored, always from ground truth
	â€¢	Text overlay shows t (frame), masked/observed status, and which conditioning was used

â¸»

6) Key shapes (for the technically curious)

For each sample:
	â€¢	Input x_in: shape (T, A*3 + R)
	â€¢	A*2 : all player coordinates (masked positions zeroed out)
	â€¢	A   : observation flags (1 = observed, 0 = masked)
	â€¢	R   : 40-way one-hot region for the masked agent
	â€¢	Target y_gt: (T, A*2) (full coordinates)
	â€¢	Loss mask loss_mask: (T, A*2) (1 where we supervise the masked agent)

The Transformer predicts (T, A*2); Diffusion variant is also provided.

â¸»

7) Common options
	â€¢	--masked_agent INT : which player to hide/predict
	â€¢	--mask_start, --mask_end : frames (1-based masking; frame 0 always observed)
	â€¢	--gif_trail INT : number of trailing segments to draw in the GIF
	â€¢	--viz_show_ids : overlay numeric player IDs
	â€¢	--save_npy / --save_npz : dump arrays for downstream analysis
	â€¢	--device auto|cpu|cuda : device selection

â¸»

8) Troubleshooting
	â€¢	My GIF is empty / not found: Make sure --court_png points to a real file (e.g., court.png).
	â€¢	Region length mismatch: If you pass --region_ids_json, its length must equal the sequenceâ€™s T.
	â€¢	OpenAI errors: Ensure OPENAI_API_KEY is exported and you have access to the gpt-4.1-mini model.
	â€¢	Coordinates look wrong: We automatically normalize to [0,1]. If your data is already normalized, thatâ€™s fine.

â¸»

9) Folder structure (suggested)

.
â”œâ”€â”€ court.png
â”œâ”€â”€ dataset_text_imputer.py
â”œâ”€â”€ model.py
â”œâ”€â”€ experiment.py
â”œâ”€â”€ inference.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ outputs/
â”‚   â””â”€â”€ vec_xl_baseline/
â”‚       â”œâ”€â”€ best.pt
â”‚       â””â”€â”€ last.pt
â””â”€â”€ test.gif   â† produced by inference.py


â¸»

10) License & attribution
	â€¢	Research/education use is encouraged. Check your datasetâ€™s terms.
	â€¢	This repo includes no official NBA assets; court.png should be a generic court image.

â¸»

TL;DR
	1.	Install deps (optional: set OPENAI_API_KEY)
	2.	Train with experiment.py
	3.	Run inference.py to produce test.gif
	4.	Green = ground truth; Blue = prediction; Regions = simple 40-bin grid

Happy hooping ğŸ€